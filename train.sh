python luke/cli.py pretrain wiki/ model/ \
	--batch-size 16 \
	--gradient-accumulation-steps 1 \
	--bert-model-name xlm-roberta-base \
	--fp16 

